{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67af5564",
   "metadata": {},
   "source": [
    "# Youtube Data Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996904b",
   "metadata": {},
   "source": [
    "## Modules\n",
    "Below are modules needed to communicate with youtube API and export data to csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d042992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (2.68.0)\n",
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.70.0-py2.py3-none-any.whl (10.7 MB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.10.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.20.4)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-python-client) (1.33.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
      "Requirement already satisfied: protobuf<5.0.0dev,>=3.20.1 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.21.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.56.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (61.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nhat minh\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2021.10.8)\n",
      "Installing collected packages: google-api-python-client\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 2.68.0\n",
      "    Uninstalling google-api-python-client-2.68.0:\n",
      "      Successfully uninstalled google-api-python-client-2.68.0\n",
      "Successfully installed google-api-python-client-2.70.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b88e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedead0",
   "metadata": {},
   "source": [
    "## Search for the most watched videos\n",
    "`get_videos_id` returns search results for IDs of approximately 200 videos which have the most views in the US in a given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f64160",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'your_API_key'\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05916a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_id(youtube, year):\n",
    "    video_list =[]\n",
    "    next_page_token = None\n",
    "    count = 1\n",
    "    request = youtube.search().list(\n",
    "        part = \"snippet\",\n",
    "        publishedAfter = str(year) + \"-01-01T00:00:00Z\",\n",
    "        publishedBefore = str(year) + \"-12-31T23:59:59Z\",\n",
    "        regionCode=\"US\",\n",
    "        order = \"viewCount\",\n",
    "        maxResults = 50, # Google allows a maximum of 50 results per page\n",
    "        pageToken = next_page_token, #each page has a token to retrieve data\n",
    "        type = \"video\")\n",
    "    response = request.execute()\n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        video_data = dict(video_title = response['items'][i]['snippet']['title'],\n",
    "                          video_id = response['items'][i]['id']['videoId'],\n",
    "                          publish_date = response['items'][i]['snippet']['publishedAt'])\n",
    "        \n",
    "        video_list.append(video_data)\n",
    "    \n",
    "    count += 1\n",
    "    while count <= 4: \n",
    "        \n",
    "        next_page_token = response['nextPageToken']\n",
    "        request = youtube.search().list(\n",
    "            part = \"snippet\",\n",
    "            publishedAfter = str(year) + \"-01-01T00:00:00Z\",\n",
    "            publishedBefore = str(year) + \"-12-31T23:59:59Z\",\n",
    "            regionCode=\"US\",\n",
    "            order = \"viewCount\",\n",
    "            pageToken = next_page_token,\n",
    "            maxResults = 50,\n",
    "            type = \"video\")\n",
    "        response = request.execute()\n",
    "    \n",
    "        for i in range(len(response['items'])):\n",
    "            video_data = dict(video_title = response['items'][i]['snippet']['title'],\n",
    "                              video_id = response['items'][i]['id']['videoId'],\n",
    "                              publish_date = response['items'][i]['snippet']['publishedAt'])\n",
    "            video_list.append(video_data)\n",
    "        count += 1\n",
    "        \n",
    "    return video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9114206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Store results---------#\n",
    "years = [2018,2019,2020,2021,2022]\n",
    "results = []\n",
    "for year in years:\n",
    "    results.extend(get_videos_id(youtube, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ae4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Export results---------#\n",
    "file = \"YouTube.csv\"\n",
    "def writeCSV(results, filename):\n",
    "    for i in range(len(results)):\n",
    "        headers = ['video_title', 'video_id', 'publish_date']\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as output:\n",
    "        writer = csv.DictWriter(output, fieldnames = headers)\n",
    "        writer.writeheader()\n",
    "        for i in range(len(results)):\n",
    "            writer.writerow(results[i])\n",
    "writeCSV(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c398ef3",
   "metadata": {},
   "source": [
    "Read the search data above and display the first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d32f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_id</th>\n",
       "      <th>publish_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASA Live: Official Stream of NASA TV</td>\n",
       "      <td>21X5lGlDOfg</td>\n",
       "      <td>2018-12-28T18:40:15Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pocoyó -   Porquera en la tubería (S04E05)</td>\n",
       "      <td>DTyy5Hf46Fs</td>\n",
       "      <td>2018-06-17T11:41:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rap Live Radio 24/7 | Hip-Hop &amp;amp; Popular Ra...</td>\n",
       "      <td>05689ErDUdM</td>\n",
       "      <td>2018-11-30T21:26:38Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         video_title     video_id  \\\n",
       "0              NASA Live: Official Stream of NASA TV  21X5lGlDOfg   \n",
       "1         Pocoyó -   Porquera en la tubería (S04E05)  DTyy5Hf46Fs   \n",
       "2  Rap Live Radio 24/7 | Hip-Hop &amp; Popular Ra...  05689ErDUdM   \n",
       "\n",
       "           publish_date  \n",
       "0  2018-12-28T18:40:15Z  \n",
       "1  2018-06-17T11:41:25Z  \n",
       "2  2018-11-30T21:26:38Z  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"YouTube.csv\")\n",
    "df.head(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c610c",
   "metadata": {},
   "source": [
    "## Get details of the most watched videos\n",
    "Search function has its limitation that it can return only video IDs, not their details. To get video details, we need another function, `get_videos`, which takes the above ID list as inputs and returns the respective videos' data. This function allows us to define which information we want to gather. In this project, we will get data of the following:\n",
    "<ul>\n",
    "    <li>Video Title</li>\n",
    "    <li>Video ID</li>\n",
    "    <li>Publish Date</li>\n",
    "    <li>Channel Title</li>\n",
    "    <li>Channel ID</li>\n",
    "    <li>Video Category</li>\n",
    "    <li>Video Duration</li>\n",
    "    <li>Number of Views</li>\n",
    "    <li>Number of Likes</li>\n",
    "    <li>Number of Comments</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4adf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(youtube, video_id):\n",
    "     \n",
    "    request = youtube.videos().list(\n",
    "        part = \"snippet,contentDetails,statistics\",\n",
    "        id = video_id)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_data = dict(vid_title = response['items'][0]['snippet']['title'],\n",
    "                      vid_id = video_id,\n",
    "                      publish_date = response['items'][0]['snippet']['publishedAt'],\n",
    "                      channel_title = response['items'][0]['snippet']['channelTitle'],\n",
    "                      channel_id = response['items'][0]['snippet']['channelId'],\n",
    "                      category_id = response['items'][0]['snippet']['categoryId'],\n",
    "                      duration = response['items'][0]['contentDetails']['duration'])\n",
    "    \n",
    "    # Some videos are made private though having high views:\n",
    "    if 'viewCount' in response['items'][0]['statistics'].keys():\n",
    "        video_data['views'] = response['items'][0]['statistics']['viewCount']\n",
    "    else:\n",
    "        video_data['views'] = 'Private'\n",
    "        \n",
    "    # Not every video has likes/dislikes enabled\n",
    "    if 'likeCount' in response['items'][0]['statistics'].keys():\n",
    "        video_data['likes'] = response['items'][0]['statistics']['likeCount']\n",
    "    else:\n",
    "        video_data['likes'] = 'Disabled'\n",
    "    \n",
    "    # Not every video has comments enabled    \n",
    "    if 'commentCount' in response['items'][0]['statistics'].keys():\n",
    "        video_data['comments'] = response['items'][0]['statistics']['commentCount']\n",
    "    else:\n",
    "        video_data['comments'] = 'Disabled'\n",
    "        \n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924408ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Store video data---------#\n",
    "video_list = []\n",
    "for video_id in df['video_id']:\n",
    "    video_list.append(get_videos(youtube, video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7738ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Export data---------#\n",
    "file = \"Youtube_video_data.csv\"\n",
    "def writeCSV(results, filename):\n",
    "    for i in range(len(video_list)):\n",
    "        headers = ['vid_title', 'vid_id', 'publish_date', 'channel_title','channel_id','category_id','duration','views','likes','comments']\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as output:\n",
    "        writer = csv.DictWriter(output, fieldnames = headers)\n",
    "        writer.writeheader()\n",
    "        for i in range(len(video_list)):\n",
    "            writer.writerow(video_list[i])\n",
    "writeCSV(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14a0b6",
   "metadata": {},
   "source": [
    "Read the data above and display the first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cadfd55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vid_title</th>\n",
       "      <th>vid_id</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASA Live: Official Stream of NASA TV</td>\n",
       "      <td>21X5lGlDOfg</td>\n",
       "      <td>2018-12-28T18:40:15Z</td>\n",
       "      <td>NASA</td>\n",
       "      <td>UCLA_DiR1FfKNvjuUpBHmylQ</td>\n",
       "      <td>28</td>\n",
       "      <td>P0D</td>\n",
       "      <td>136274799</td>\n",
       "      <td>2094730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pocoyó -   Porquera en la tubería (S04E05)</td>\n",
       "      <td>DTyy5Hf46Fs</td>\n",
       "      <td>2018-06-17T11:41:25Z</td>\n",
       "      <td>Pocoyo Series</td>\n",
       "      <td>UCzKG_Nq4SAWE-VBEuHo3jYA</td>\n",
       "      <td>1</td>\n",
       "      <td>PT7M9S</td>\n",
       "      <td>118073485</td>\n",
       "      <td>504562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rap Live Radio 24/7 | Hip-Hop &amp; Popular Rap Mu...</td>\n",
       "      <td>05689ErDUdM</td>\n",
       "      <td>2018-11-30T21:26:38Z</td>\n",
       "      <td>UPROXX Music</td>\n",
       "      <td>UCI2HI_aQ_S3v4vfDQgNtK1g</td>\n",
       "      <td>10</td>\n",
       "      <td>P0D</td>\n",
       "      <td>28581927</td>\n",
       "      <td>337831</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           vid_title       vid_id  \\\n",
       "0              NASA Live: Official Stream of NASA TV  21X5lGlDOfg   \n",
       "1         Pocoyó -   Porquera en la tubería (S04E05)  DTyy5Hf46Fs   \n",
       "2  Rap Live Radio 24/7 | Hip-Hop & Popular Rap Mu...  05689ErDUdM   \n",
       "\n",
       "           publish_date  channel_title                channel_id  category_id  \\\n",
       "0  2018-12-28T18:40:15Z           NASA  UCLA_DiR1FfKNvjuUpBHmylQ           28   \n",
       "1  2018-06-17T11:41:25Z  Pocoyo Series  UCzKG_Nq4SAWE-VBEuHo3jYA            1   \n",
       "2  2018-11-30T21:26:38Z   UPROXX Music  UCI2HI_aQ_S3v4vfDQgNtK1g           10   \n",
       "\n",
       "  duration      views    likes comments  \n",
       "0      P0D  136274799  2094730        0  \n",
       "1   PT7M9S  118073485   504562        0  \n",
       "2      P0D   28581927   337831        7  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv(\"Youtube_video_data.csv\")\n",
    "df_1.head(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65225a48",
   "metadata": {},
   "source": [
    "## Get video category list\n",
    "The above data contain category IDs but not their names. `video_categories` function returns a list of dictionaries mapping category IDs and their respective names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efeab91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_categories(youtube, region_code):\n",
    "    categories = []\n",
    "    request = youtube.videoCategories().list(\n",
    "        part = \"snippet\",\n",
    "        regionCode = region_code)\n",
    "    response = request.execute()\n",
    "    for i in range(len(response['items'])):\n",
    "        category_info = dict(category_id = response['items'][i]['id'],\n",
    "                             category_name = response['items'][i]['snippet']['title'])\n",
    "        categories.append(category_info)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef5a4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_us = video_categories(youtube, 'US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1285dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Export data---------#\n",
    "file = \"Video_Categories.csv\"\n",
    "def writeCSV(categories_us, filename):\n",
    "    for i in range(len(categories_us)):\n",
    "        headers = ['category_id', 'category_name']\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as output:\n",
    "        writer = csv.DictWriter(output, fieldnames = headers)\n",
    "        writer.writeheader()\n",
    "        for i in range(len(categories_us)):\n",
    "            writer.writerow(categories_us[i])\n",
    "writeCSV(categories_us, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a93ed7",
   "metadata": {},
   "source": [
    "Read the data above and display the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70c87e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id     category_name\n",
       "0            1  Film & Animation\n",
       "1            2  Autos & Vehicles\n",
       "2           10             Music"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.read_csv(\"Video_Categories.csv\")\n",
    "df_2.head(3) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
